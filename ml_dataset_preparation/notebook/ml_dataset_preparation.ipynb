import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.font_manager as fm
import matplotlib.colors as mcolors
import os

accountinfo = pd.read_csv("../data/ravenstack_accounts.csv")
subscriptions = pd.read_csv("../data/ravenstack_subscriptions.csv")
churnevents = pd.read_csv("../data/ravenstack_churn_events.csv")
featureusage = pd.read_csv("../data/ravenstack_feature_usage.csv")
supportdata = pd.read_csv("../data/ravenstack_support_tickets.csv")

# 2. Custom viisulaisation theme

def set_dark_theme():

    # Backgrounds
    plt.rcParams["figure.facecolor"] = "#0C0420"
    plt.rcParams["axes.facecolor"] = "#0A0318"
    plt.rcParams["savefig.facecolor"] = "#0C0420"

    # Text colors (silver aesthetic)
    plt.rcParams["text.color"] = "#E6E6E6"
    plt.rcParams["axes.labelcolor"] = "#E6E6E6"
    plt.rcParams["xtick.color"] = "#E6E6E6"
    plt.rcParams["ytick.color"] = "#E6E6E6"

    # Title style
    plt.rcParams["axes.titleweight"] = "bold"
    plt.rcParams["axes.titlesize"] = 18

    # Grid lines
    plt.rcParams["grid.color"] = "#FFFFFF"
    plt.rcParams["grid.alpha"] = 0.08
    plt.rcParams["grid.linestyle"] = "--"

    # Bars / lines sharpness
    plt.rcParams["axes.edgecolor"] = "#E6E6E6"
    plt.rcParams["patch.force_edgecolor"] = True
    plt.rcParams["patch.edgecolor"] = "#0C0420"

    # Base font
    plt.rcParams["font.family"] = "Lora"

font_paths = [
    r"C:\Users\Lenovo\Downloads\Lora,Montserrat,Open_Sans,Playfair_Display,Stack_Sans_Notch\Lora\Lora-Italic-VariableFont_wght.ttf"
]

for p in font_paths:
    if os.path.exists(p):
        fm.fontManager.addfont(p)

# activate theme AFTER fonts
set_dark_theme()

# ensure churn_date is datetime
churnevents["churn_date"] = pd.to_datetime(churnevents["churn_date"])

# reference date (for retained users timeline)
reference_date = churnevents["churn_date"].max()
reference_date

# ======================================================
# 2. Helper Functions (Buckets + Level Insight)
# ======================================================

def bucket_ticket_count(x):
    if x <= 2:
        return "Stable"
    elif x <= 4:
        return "Elevated"
    elif x <= 6:
        return "High Risk"
    elif x <= 8:
        return "Critical"
    else:
        return "Severe Critical"

def usage_bucket(x):
    if x <= 25:
        return "disengaged"
    elif x <= 40:
        return "inconsistent"
    elif x <= 60:
        return "stable usage"
    elif x <= 80:
        return "engaged"
    else:
        return "dependency stress"

def error_bucket(x):
    if x == 0:
        return "No Errors"
    elif x <= 5:
        return "Low Errors"
    elif x <= 10:
        return "Medium Errors"
    elif x <= 20:
        return "High Errors"
    else:
        return "Severe Errors"

def satisfaction_bucket(x):
    if x <= 1:
        return "Extremely Unhappy"
    elif x <= 2:
        return "Unhappy"
    elif x <= 3:
        return "Neutral"
    elif x <= 4:
        return "Satisfied"
    else:
        return "Very Satisfied"

def level_insight_func(row):
    if row["downgrade_flag"] and not row["upgrade_flag"]:
        return "Downgraded"
    if row["upgrade_flag"] and not row["downgrade_flag"]:
        return "Upgraded"
    if not row["upgrade_flag"] and not row["downgrade_flag"]:
        return "No Action"
    return "Mixed — Needs Review"

# ======================================================
# 3. Base Split: Churned vs Retained Subscriptions
# ======================================================

churned_subs  = subscriptions[subscriptions["churn_flag"] == True].copy()
retained_subs = subscriptions[subscriptions["churn_flag"] == False].copy()

print("Churned subscriptions:", churned_subs.shape[0])
print("Retained subscriptions:", retained_subs.shape[0])

# ======================================================
# 4. CHURNED USERS – Behaviour Aggregation
# ======================================================

# 4.1 Feature usage for churned subs
churn_feat = (
    pd.merge(churned_subs, featureusage, on="subscription_id", how="inner")
    .drop_duplicates()
)

churn_feat["usage_duration_min"] = churn_feat["usage_duration_secs"] / 60

# 4.2 Support merge
churn_support = pd.merge(churn_feat, supportdata, on="account_id", how="inner")

churn_support["usage_duration_min"] = churn_support["usage_duration_secs"] / 60
churn_support["satisfaction_score"] = churn_support["satisfaction_score"].fillna(0)

churn_support["submitted_at"] = pd.to_datetime(churn_support["submitted_at"])
churn_support["closed_at"]    = pd.to_datetime(churn_support["closed_at"])
churn_support["ticket_month"] = churn_support["submitted_at"].dt.to_period("M").astype(str)

churn_support = churn_support.drop_duplicates(subset="ticket_id")

churn_support.shape

# 4.3 Aggregated behaviour per churned account (overall window)

# ticket volume per account
ch_ticket_count = (
    churn_support.groupby("account_id")["ticket_id"]
    .count()
    .sort_values()
    .reset_index()
    .rename(columns={"ticket_id": "ticket_count"})
)
ch_ticket_count["ticket_bucket"] = ch_ticket_count["ticket_count"].apply(bucket_ticket_count)

# avg usage per account
ch_usage = (
    churn_support.groupby("account_id")["usage_duration_min"]
    .mean()
    .reset_index()
    .rename(columns={"usage_duration_min": "usage_avg_min"})
)
ch_usage["usage_bucket"] = ch_usage["usage_avg_min"].apply(usage_bucket)

# total errors per account
ch_error = (
    churn_support.groupby("account_id")["error_count"]
    .sum()
    .reset_index()
    .rename(columns={"error_count": "error_sum"})
)
ch_error["error_bucket"] = ch_error["error_sum"].apply(error_bucket)

# avg satisfaction per account
ch_sat = (
    churn_support.groupby("account_id")["satisfaction_score"]
    .mean()
    .reset_index()
    .rename(columns={"satisfaction_score": "satisfaction_avg"})
)
ch_sat["satisfaction_bucket"] = ch_sat["satisfaction_avg"].apply(satisfaction_bucket)

# combine
ch_support_analysis = (
    ch_ticket_count
    .merge(ch_usage, on="account_id", how="inner")
    .merge(ch_error, on="account_id", how="inner")
    .merge(ch_sat, on="account_id", how="inner")
)

ch_support_analysis.head()

# ======================================================
# 5. CHURNED – Last 3 Months Before Churn (Dynamic Behaviour)
# ======================================================

# 5.1 Ticket-level frame with timeline
ch_ticket_churn = pd.merge(churnevents, churn_support, on="account_id", how="inner")

ch_ticket_churn["submitted_at"] = pd.to_datetime(ch_ticket_churn["submitted_at"])
ch_ticket_churn["churn_date"]   = pd.to_datetime(ch_ticket_churn["churn_date"])

ch_ticket_churn["ticket_month_int"] = ch_ticket_churn["submitted_at"].dt.to_period("M").astype(int)
ch_ticket_churn["churn_month_int"]  = ch_ticket_churn["churn_date"].dt.to_period("M").astype(int)

ch_ticket_churn["months_before_churn"] = (
    ch_ticket_churn["ticket_month_int"] - ch_ticket_churn["churn_month_int"]
)

# Keep last 12 months before churn
ch_pre12 = ch_ticket_churn[
    (ch_ticket_churn["months_before_churn"] < 0) &
    (ch_ticket_churn["months_before_churn"] >= -12)
].copy()

print(ch_pre12["months_before_churn"].describe())

# 5.2 Aggregate last 3 months (−3, −2, −1)

ch_last3 = ch_pre12[ch_pre12["months_before_churn"].between(-3, -1)].copy()

ch_last3_agg = (
    ch_last3.groupby("account_id")
    .agg(
        last3_ticket_count=("ticket_id", "count"),
        last3_usage_avg_min=("usage_duration_min", "mean"),
        last3_error_sum=("error_count", "sum"),
        last3_satisfaction_avg=("satisfaction_score", "mean"),
    )
    .reset_index()
)

# bucket last 3 months
ch_last3_agg["last3_ticket_bucket"]      = ch_last3_agg["last3_ticket_count"].apply(bucket_ticket_count)
ch_last3_agg["last3_usage_bucket"]       = ch_last3_agg["last3_usage_avg_min"].apply(usage_bucket)
ch_last3_agg["last3_error_bucket"]       = ch_last3_agg["last3_error_sum"].apply(error_bucket)
ch_last3_agg["last3_satisfaction_bucket"] = ch_last3_agg["last3_satisfaction_avg"].apply(satisfaction_bucket)

ch_last3_agg.head()

# 5.2 Aggregate last 3 months (−3, −2, −1)

ch_last3 = ch_pre12[ch_pre12["months_before_churn"].between(-3, -1)].copy()

ch_last3_agg = (
    ch_last3.groupby("account_id")
    .agg(
        last3_ticket_count=("ticket_id", "count"),
        last3_usage_avg_min=("usage_duration_min", "mean"),
        last3_error_sum=("error_count", "sum"),
        last3_satisfaction_avg=("satisfaction_score", "mean"),
    )
    .reset_index()
)

# bucket last 3 months
ch_last3_agg["last3_ticket_bucket"]      = ch_last3_agg["last3_ticket_count"].apply(bucket_ticket_count)
ch_last3_agg["last3_usage_bucket"]       = ch_last3_agg["last3_usage_avg_min"].apply(usage_bucket)
ch_last3_agg["last3_error_bucket"]       = ch_last3_agg["last3_error_sum"].apply(error_bucket)
ch_last3_agg["last3_satisfaction_bucket"] = ch_last3_agg["last3_satisfaction_avg"].apply(satisfaction_bucket)

ch_last3_agg.head()

# 5.3 Final churned dataset for ML

churned_dataset = ch_base.merge(ch_last3_agg, on="account_id", how="left")

# fill NaNs for accounts with no activity in last 3 months
for col in ["last3_ticket_count", "last3_error_sum"]:
    churned_dataset[col] = churned_dataset[col].fillna(0)

for col in ["last3_usage_avg_min", "last3_satisfaction_avg"]:
    churned_dataset[col] = churned_dataset[col].fillna(0)

for col in [
    "last3_ticket_bucket",
    "last3_usage_bucket",
    "last3_error_bucket",
    "last3_satisfaction_bucket",
]:
    churned_dataset[col] = churned_dataset[col].fillna("No Recent Activity")

churned_dataset["churn_flag"] = 1

churned_dataset.head()

churned_dataset.to_csv("churn_support_dataset.csv")

# ======================================================
# 6. RETAINED USERS – Behaviour Aggregation
# ======================================================

# 6.1 Feature + support for retained subs
re_feat = (
    pd.merge(retained_subs, featureusage, on="subscription_id", how="inner")
    .drop_duplicates()
)
re_feat["usage_duration_min"] = re_feat["usage_duration_secs"] / 60

re_support = pd.merge(re_feat, supportdata, on="account_id", how="inner")

re_support["usage_duration_min"] = re_support["usage_duration_secs"] / 60
re_support["satisfaction_score"] = re_support["satisfaction_score"].fillna(0)

re_support["submitted_at"] = pd.to_datetime(re_support["submitted_at"])
re_support["closed_at"]    = pd.to_datetime(re_support["closed_at"])
re_support["ticket_month"] = re_support["submitted_at"].dt.to_period("M").astype(str)

re_support = re_support.drop_duplicates(subset="ticket_id")

re_support.shape

# 6.2 Aggregated behaviour per retained account (overall)

re_ticket_count = (
    re_support.groupby("account_id")["ticket_id"]
    .count()
    .sort_values()
    .reset_index()
    .rename(columns={"ticket_id": "ticket_count"})
)
re_ticket_count["ticket_bucket"] = re_ticket_count["ticket_count"].apply(bucket_ticket_count)

re_usage = (
    re_support.groupby("account_id")["usage_duration_min"]
    .mean()
    .reset_index()
    .rename(columns={"usage_duration_min": "usage_avg_min"})
)
re_usage["usage_bucket"] = re_usage["usage_avg_min"].apply(usage_bucket)

re_error = (
    re_support.groupby("account_id")["error_count"]
    .sum()
    .reset_index()
    .rename(columns={"error_count": "error_sum"})
)
re_error["error_bucket"] = re_error["error_sum"].apply(error_bucket)

re_sat = (
    re_support.groupby("account_id")["satisfaction_score"]
    .mean()
    .reset_index()
    .rename(columns={"satisfaction_score": "satisfaction_avg"})
)
re_sat["satisfaction_bucket"] = re_sat["satisfaction_avg"].apply(satisfaction_bucket)

re_support_analysis = (
    re_ticket_count
    .merge(re_usage, on="account_id", how="inner")
    .merge(re_error, on="account_id", how="inner")
    .merge(re_sat, on="account_id", how="inner")
)

re_support_analysis.head()

# ======================================================
# 7. RETAINED – Last 3 Months Before Reference Date
# ======================================================

# Convert to "ordinal-like" month index
re_support["ticket_month_int"] = re_support["submitted_at"].dt.to_period("M").apply(lambda p: p.ordinal)
reference_month_int = reference_date.to_period("M").ordinal

re_support["months_before_reference"] = (
    re_support["ticket_month_int"] - reference_month_int
)

# last 12 months before reference
re_pre12 = re_support[
    (re_support["months_before_reference"] < 0) &
    (re_support["months_before_reference"] >= -12)
].copy()

# last 3 months relative to reference date
re_last3 = re_pre12[
    re_pre12["months_before_reference"].between(-3, -1)
].copy()

re_last3_agg = (
    re_last3.groupby("account_id")
    .agg(
        last3_ticket_count=("ticket_id", "count"),
        last3_usage_avg_min=("usage_duration_min", "mean"),
        last3_error_sum=("error_count", "sum"),
        last3_satisfaction_avg=("satisfaction_score", "mean"),
    )
    .reset_index()
)

re_last3_agg["last3_ticket_bucket"]      = re_last3_agg["last3_ticket_count"].apply(bucket_ticket_count)
re_last3_agg["last3_usage_bucket"]       = re_last3_agg["last3_usage_avg_min"].apply(usage_bucket)
re_last3_agg["last3_error_bucket"]       = re_last3_agg["last3_error_sum"].apply(error_bucket)
re_last3_agg["last3_satisfaction_bucket"] = re_last3_agg["last3_satisfaction_avg"].apply(satisfaction_bucket)

re_last3_agg.head()

# 7.1 Final retained dataset

retained_dataset = re_support_analysis.merge(re_last3_agg, on="account_id", how="left")

for col in ["last3_ticket_count", "last3_error_sum"]:
    retained_dataset[col] = retained_dataset[col].fillna(0)

for col in ["last3_usage_avg_min", "last3_satisfaction_avg"]:
    retained_dataset[col] = retained_dataset[col].fillna(0)

for col in [
    "last3_ticket_bucket",
    "last3_usage_bucket",
    "last3_error_bucket",
    "last3_satisfaction_bucket",
]:
    retained_dataset[col] = retained_dataset[col].fillna("No Recent Activity")

retained_dataset["churn_flag"] = 0

retained_dataset.head()


retained_dataset.to_csv("retained_support_dataset.csv")
# ======================================================
# 8. COMBINED ML DATASET + SAVE
# ======================================================

full_ml_dataset = pd.concat(
    [churned_dataset, retained_dataset],
    ignore_index=True
)

# (optional) attach account-level info like industry, plan_tier, etc.
if "account_id" in accountinfo.columns:
    full_ml_dataset = full_ml_dataset.merge(
        accountinfo.drop_duplicates("account_id"),
        on="account_id",
        how="left"
    )

print("Churned dataset shape :", churned_dataset.shape)
print("Retained dataset shape:", retained_dataset.shape)
print("Full ML dataset shape :", full_ml_dataset.shape)

full_ml_dataset.head()

import os

full_ml_dataset.to_csv("ravenstack_churn_ml_dataset_90day.csv",
              index=False, encoding="utf-8")
