# 1. Load Data & Setup

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.font_manager as fm
import matplotlib.colors as mcolors
import os

accountinfo = pd.read_csv("../data/ravenstack_accounts.csv")
subscriptions = pd.read_csv("../data/ravenstack_subscriptions.csv")
churnevents = pd.read_csv("../data/ravenstack_churn_events.csv")
featureusage = pd.read_csv("../data/ravenstack_feature_usage.csv")
supportdata = pd.read_csv("../data/ravenstack_support_tickets.csv")

# 2. Custom viisulaisation theme


def set_dark_theme():

    # Backgrounds
    plt.rcParams["figure.facecolor"] = "#0C0420"
    plt.rcParams["axes.facecolor"] = "#0A0318"
    plt.rcParams["savefig.facecolor"] = "#0C0420"

    # Text colors (silver aesthetic)
    plt.rcParams["text.color"] = "#E6E6E6"
    plt.rcParams["axes.labelcolor"] = "#E6E6E6"
    plt.rcParams["xtick.color"] = "#E6E6E6"
    plt.rcParams["ytick.color"] = "#E6E6E6"

    # Title style
    plt.rcParams["axes.titleweight"] = "bold"
    plt.rcParams["axes.titlesize"] = 18

    # Grid lines
    plt.rcParams["grid.color"] = "#FFFFFF"
    plt.rcParams["grid.alpha"] = 0.08
    plt.rcParams["grid.linestyle"] = "--"

    # Bars / lines sharpness
    plt.rcParams["axes.edgecolor"] = "#E6E6E6"
    plt.rcParams["patch.force_edgecolor"] = True
    plt.rcParams["patch.edgecolor"] = "#0C0420"

    # Base font
    plt.rcParams["font.family"] = "Lora"

# =====================================================
# 2. LOAD YOUR DOWNLOADED FONTS PROPERLY
# =====================================================
font_paths = [
    r"C:\Users\Lenovo\Downloads\Lora,Montserrat,Open_Sans,Playfair_Display,Stack_Sans_Notch\Lora\Lora-Italic-VariableFont_wght.ttf"
]

for p in font_paths:
    if os.path.exists(p):
        fm.fontManager.addfont(p)

# activate theme AFTER fonts
set_dark_theme()

# 3. Churned Customers — Feature Usage & Risk Analysis
churned = subscriptions[subscriptions['churn_flag'] == True]

# Merge with feature usage
feature_churned = pd.merge(churned, featureusage, on="subscription_id", how="inner").drop_duplicates()

# Convert usage duration
feature_churned['usage_duration_min'] = feature_churned['usage_duration_secs'] / 60

feature_churn_cnt = (
    feature_churned.groupby("feature_name")["account_id"]
    .count().sort_values(ascending=False).reset_index()
)

#feature_churn_cnt

feature_churn_avg_usage = (
    feature_churned.groupby("feature_name")["usage_duration_min"]
    .mean().sort_values(ascending=False).reset_index()
)

#feature_churn_avg_usage

churn_support = pd.merge(feature_churned, supportdata, on="account_id", how="inner")

feature_churn_ticket = (
    churn_support.groupby("feature_name")["ticket_id"]
    .nunique().sort_values(ascending=False).reset_index()
)

#feature_churn_ticket

feature_churn_sat = (
    churn_support.dropna(subset=["satisfaction_score"])
    .groupby("feature_name")["satisfaction_score"]
    .mean().sort_values(ascending=True).reset_index()
)

#feature_churn_sat

feature_churn_errors = (
    churn_support.groupby("feature_name")["error_count"]
    .sum().sort_values(ascending=True).reset_index()
)

#feature_churn_errors

rank_churn_list = [
        "feature_4","feature_2","feature_37","feature_10","feature_36","feature_12",
        "feature_6","feature_30","feature_35","feature_1","feature_32","feature_29",
        "feature_11","feature_40","feature_20","feature_15","feature_38","feature_19",
        "feature_8","feature_31","feature_28","feature_9","feature_13","feature_22",
        "feature_25","feature_14","feature_33","feature_18","feature_21","feature_23",
        "feature_39","feature_5","feature_34","feature_26","feature_24","feature_7",
        "feature_16","feature_17","feature_3","feature_27"
    ]

rank_usage_list = [
        "feature_24","feature_21","feature_8","feature_16","feature_11","feature_32",
        "feature_25","feature_26","feature_7","feature_18","feature_22","feature_15",
        "feature_37","feature_19","feature_14","feature_38","feature_33","feature_23",
        "feature_2","feature_34","feature_29","feature_4","feature_28","feature_35",
        "feature_12","feature_30","feature_39","feature_5","feature_6","feature_13",
        "feature_27","feature_17","feature_9","feature_40","feature_10","feature_36",
        "feature_1","feature_20","feature_3","feature_31"
    ]
rank_tickets_list = [
        "feature_4","feature_32","feature_1","feature_37","feature_10","feature_6",
        "feature_29","feature_20","feature_13","feature_12","feature_36","feature_40",
        "feature_15","feature_30","feature_11","feature_2","feature_34","feature_35",
        "feature_8","feature_38","feature_28","feature_39","feature_22","feature_14",
        "feature_19","feature_23","feature_9","feature_24","feature_18","feature_21",
        "feature_33","feature_25","feature_31","feature_26","feature_5","feature_17",
        "feature_7","feature_3","feature_16","feature_27"
    ]

rank_satisfaction_list = [
        "feature_33","feature_17","feature_21","feature_32","feature_16","feature_13",
        "feature_8","feature_20","feature_30","feature_12","feature_23","feature_5",
        "feature_28","feature_40","feature_34","feature_3","feature_22","feature_1",
        "feature_4","feature_14","feature_38","feature_26","feature_10","feature_25",
        "feature_11","feature_2","feature_7","feature_18","feature_15","feature_9",
        "feature_36","feature_27","feature_19","feature_31","feature_35","feature_24",
        "feature_29","feature_39","feature_37","feature_6"
    ]
rank_errors_list  = [
        "feature_5","feature_23","feature_33","feature_3","feature_6","feature_8",
        "feature_35","feature_31","feature_7","feature_15","feature_17","feature_16",
        "feature_18","feature_38","feature_14","feature_13","feature_19","feature_29",
        "feature_27","feature_21","feature_22","feature_37","feature_40","feature_30",
        "feature_24","feature_28","feature_26","feature_9","feature_32","feature_10",
        "feature_39","feature_12","feature_11","feature_2","feature_1","feature_4",
        "feature_25","feature_34","feature_20","feature_36"
    ]
	
	
def list_to_rank_dict(lst):
    return {f: i+1 for i, f in enumerate(lst)}

rank_churn = list_to_rank_dict(rank_churn_list)
rank_usage = list_to_rank_dict(rank_usage_list)
rank_tickets = list_to_rank_dict(rank_tickets_list)
rank_satisfaction = list_to_rank_dict(rank_satisfaction_list)
rank_errors = list_to_rank_dict(rank_errors_list)

all_features = rank_churn_list

df_churn = pd.DataFrame({
    "feature_name": all_features,
    "rank_churn": [rank_churn[f] for f in all_features],
    "rank_usage": [rank_usage[f] for f in all_features],
    "rank_errors": [rank_errors[f] for f in all_features],
    "rank_tickets": [rank_tickets[f] for f in all_features],
    "rank_satisfaction": [rank_satisfaction[f] for f in all_features],
})

# Composite risk score
df_churn["Risk_Rank"] = df_churn[[
    "rank_churn","rank_usage","rank_errors",
    "rank_tickets","rank_satisfaction"
]].mean(axis=1)

# Bucketing
def churn_bucket(score):
    if score <= 12: return "Critical"
    if score <= 18: return "High Risk"
    if score <= 22: return "Medium Risk"
    if score <= 30: return "Low Risk"
    return "No Risk"

df_churn["Risk_Bucket"] = df_churn["Risk_Rank"].apply(churn_bucket)

df_churn_final = df_churn.sort_values("Risk_Rank").reset_index(drop=True)
df_churn_final

df_churn_final.to_csv("feature_risk-rank.csv")

#Features_Risk_Heatmap

CH_df_sorted = df_churn_final.sort_values("Risk_Rank").reset_index(drop=True)
CH_heat_data = CH_df_sorted[["Risk_Rank"]].to_numpy()

boundaries = [0, 12, 18, 22, 30, 40]
bucket_colors = [
    "#00E6E6", 
    "#C56BFF", 
    "#FF6BD9",  
    "#6B8BFF",  
    "#B6FF6B", 
]
cmap = mcolors.ListedColormap(bucket_colors)
norm = mcolors.BoundaryNorm(boundaries, cmap.N)

plt.figure(figsize=(12, 22))

# Heatmap
ax = sns.heatmap(
    CH_heat_data,
    cmap=cmap,
    norm=norm,
    cbar=True,
    linewidths=0.3,
    linecolor="white",
    yticklabels=CH_df_sorted["feature_name"],
    xticklabels=["Risk_Rank"],
    annot=CH_df_sorted["Risk_Bucket"].values.reshape(-1, 1),
    fmt="",
    annot_kws={
        "color": "white",
        "fontsize": 9,
        "fontweight": "bold",
        "ha": "center",
        "va": "center"
    }
)

plt.title(
    "Churned Feature Risk Map",
    fontsize=22,
    color="white",
    pad=20
)

ax.set_xticklabels(ax.get_xticklabels(), color="white", fontsize=12)
ax.set_yticklabels(ax.get_yticklabels(), color="white", fontsize=10)

cbar = ax.collections[0].colorbar
cbar.set_ticks([6, 15, 20, 26, 35])
cbar.set_ticklabels([
    "Critical",
    "High Risk",
    "Medium Risk",
    "Low Risk",
    "No Risk"
])

for tick in cbar.ax.get_yticklabels():
    tick.set_color("white")
    tick.set_fontsize(10)

plt.tight_layout()
plt.savefig(
    "Features_Risk_Heatmap.png",
    dpi=300,
    bbox_inches="tight",
    facecolor=plt.gcf().get_facecolor()
)

plt.show()

#Risk_bucket_donut

order = [
   "Critical",
    "High Risk",
    "Medium Risk",
    "Low Risk",
    "No Risk",
]

base_colors = {
    "Critical": "#00E6E6",
    "High Risk": "#C56BFF",
    "Medium Risk": "#FF6BD9",
    "Low Risk": "#6B8BFF",
    "No Risk": "#B6FF6B"
}

bucket_counts = (
    df_churn_final["Risk_Bucket"]
    .value_counts()
    .reindex(order)
    .fillna(0)
    .astype(int)
    .values
)

labels_order = order
colors = [base_colors[k] for k in labels_order]

def lighten(hexcolor, amount=0.25):
    rgb = np.array(mcolors.to_rgb(hexcolor))
    return tuple(rgb + (1 - rgb) * amount)

outer_colors = [lighten(c, 0.35) for c in colors]

fig, ax = plt.subplots(figsize=(9, 9), facecolor="#0C0420")
ax.set_facecolor("#0C0420")

# Outer donut
wedges_outer, _ = ax.pie(
    bucket_counts,
    radius=1.0,
    colors=outer_colors,
    startangle=90,
    wedgeprops=dict(width=0.25, edgecolor="#0C0420", linewidth=1.2)
)

# Inner donut
wedges_inner, _ = ax.pie(
    bucket_counts,
    radius=0.75,
    colors=colors,
    startangle=90,
    wedgeprops=dict(width=0.35, edgecolor="#0C0420", linewidth=1.2)
)

# Center hole
ax.add_artist(plt.Circle((0, 0), 0.40, color="#0A0318", zorder=10))

total = bucket_counts.sum()

for w_outer, count, label in zip(wedges_outer, bucket_counts, labels_order):
    theta1, theta2 = w_outer.theta1, w_outer.theta2
    mid = (theta1 + theta2) / 2
    angle = np.deg2rad(mid)

    # Position between rings
    r = 0.875
    x = r * np.cos(angle)
    y = r * np.sin(angle)

    pct = f"{(count / total) * 100:.1f}%"

    # If slice is tiny, move label slightly inward
    if abs(theta2 - theta1) < 10:
        x *= 0.88
        y *= 0.88

    ax.text(
        x, y, pct,
        ha="center", va="center",
        color="white", fontsize=13, fontweight="bold",
        bbox=dict(boxstyle="round,pad=0.2", facecolor="#00000033", edgecolor="none")
    )

plt.title("Retained Feature Health Bucket Distribution",
          fontsize=26, color="#F4EBD0", pad=24, weight="bold")

legend_patches = [
    plt.Line2D([0], [0], marker='s', color='w', markerfacecolor=colors[i], markersize=14)
    for i in range(len(colors))
]

ax.legend(
    legend_patches, labels_order,
    title="Risk Buckets",
    loc="center left", bbox_to_anchor=(1.02, 0.5),
    frameon=True, facecolor="#0C0420", edgecolor="#FFFFFF40",
    fontsize=12, title_fontsize=14
)

plt.tight_layout()
plt.savefig(
    "Risk_bucket_donut.png",
    dpi=300,
    bbox_inches="tight",
    facecolor=plt.gcf().get_facecolor()
)

plt.show()	

# 4. Retained Customers — Feature Usage & Health Analysis


retained = subscriptions[subscriptions['churn_flag'] == False]

feature_retained = pd.merge(retained, featureusage, on="subscription_id", how="inner").drop_duplicates()
feature_retained['usage_duration_min'] = feature_retained['usage_duration_secs'] / 60

feature_ret_freq = (
    feature_retained.groupby("feature_name")["account_id"]
    .count().sort_values(ascending=False).reset_index()
)
#feature_ret_freq

ret_support = pd.merge(feature_retained, supportdata, on="account_id", how="inner")

feature_ret_errors = (
    ret_support.groupby("feature_name")["error_count"]
    .sum().sort_values(ascending=True).reset_index()
)
#feature_ret_errors

feature_ret_tickets = (
    ret_support.groupby("feature_name")["ticket_id"]
    .nunique().sort_values(ascending=True).reset_index()
)

#feature_ret_tickets

feature_ret_usage = (
    ret_support.groupby("feature_name")["usage_duration_min"]
    .mean().sort_values(ascending=False).reset_index()
)
#feature_ret_usage

feature_ret_sat = (
    ret_support.dropna(subset=["satisfaction_score"])
    .groupby("feature_name")["satisfaction_score"]
    .mean().sort_values(ascending=False).reset_index()
)
#feature_ret_sat

rank_retained_list  = [
        "feature_17","feature_26","feature_34","feature_32","feature_24","feature_12",
        "feature_6","feature_31","feature_38","feature_20","feature_15","feature_33",
        "feature_22","feature_36","feature_11","feature_39","feature_16","feature_29",
        "feature_7","feature_2","feature_27","feature_9","feature_37","feature_1",
        "feature_28","feature_30","feature_10","feature_40","feature_25","feature_3",
        "feature_13","feature_4","feature_14","feature_8","feature_21","feature_18",
        "feature_19","feature_5","feature_35","feature_23"
    ]

rank_errors_list   = [
        "feature_8","feature_37","feature_14","feature_20","feature_22","feature_35",
        "feature_7","feature_23","feature_1","feature_5","feature_11","feature_25",
        "feature_6","feature_36","feature_15","feature_31","feature_24","feature_33",
        "feature_18","feature_30","feature_10","feature_27","feature_39","feature_38",
        "feature_12","feature_3","feature_32","feature_19","feature_21","feature_17",
        "feature_16","feature_28","feature_29","feature_34","feature_40","feature_13",
        "feature_2","feature_9","feature_4","feature_26"
    ]

rank_tickets_list  =  [
        "feature_18","feature_23","feature_8","feature_6","feature_30","feature_35",
        "feature_40","feature_5","feature_1","feature_16","feature_4","feature_22",
        "feature_10","feature_27","feature_28","feature_20","feature_3","feature_29",
        "feature_33","feature_25","feature_31","feature_37","feature_15","feature_36",
        "feature_34","feature_21","feature_19","feature_7","feature_14","feature_24",
        "feature_39","feature_11","feature_38","feature_32","feature_2","feature_9",
        "feature_13","feature_26","feature_17","feature_12"
    ]
rank_usage_list = [
        "feature_27","feature_8","feature_24","feature_11","feature_4","feature_12",
        "feature_40","feature_33","feature_15","feature_39","feature_5","feature_6",
        "feature_30","feature_13","feature_9","feature_34","feature_26","feature_16",
        "feature_19","feature_3","feature_17","feature_7","feature_20","feature_21",
        "feature_2","feature_38","feature_28","feature_37","feature_29","feature_1",
        "feature_32","feature_35","feature_23","feature_10","feature_14","feature_18",
        "feature_25","feature_31","feature_22","feature_36"
    ]
rank_satisfaction_list  = [
        "feature_24","feature_8","feature_40","feature_18","feature_9","feature_3",
        "feature_28","feature_2","feature_13","feature_31","feature_38","feature_7",
        "feature_25","feature_39","feature_14","feature_26","feature_10","feature_20",
        "feature_27","feature_35","feature_11","feature_21","feature_33","feature_32",
        "feature_30","feature_16","feature_1","feature_37","feature_17","feature_6",
        "feature_23","feature_12","feature_29","feature_22","feature_4","feature_5",
        "feature_34","feature_36","feature_15","feature_19"
    ]    
	

def reversed_rank_dict(lst):
    base = {f: i+1 for i, f in enumerate(lst)}
    return {f: 41 - r for f, r in base.items()}

rank_retained = reversed_rank_dict(rank_retained_list)
rank_usage = reversed_rank_dict(rank_usage_list)
rank_errors = reversed_rank_dict(rank_errors_list)
rank_tickets = reversed_rank_dict(rank_tickets_list)
rank_satisfaction = reversed_rank_dict(rank_satisfaction_list)

all_features = rank_retained_list

df_ret = pd.DataFrame({
    "feature_name": all_features,
    "rank_retained": [rank_retained[f] for f in all_features],
    "rank_usage": [rank_usage[f] for f in all_features],
    "rank_errors": [rank_errors[f] for f in all_features],
    "rank_tickets": [rank_tickets[f] for f in all_features],
    "rank_satisfaction": [rank_satisfaction[f] for f in all_features],
})

df_ret["Health_Rank"] = df_ret[[
    "rank_retained","rank_usage","rank_errors",
    "rank_tickets","rank_satisfaction"
]].mean(axis=1)

def health_bucket(x):
    if x <= 12: return "Weak"
    if x <= 18: return "Below Average"
    if x <= 22: return "Average"
    if x <= 30: return "Healthy"
    return "Very Healthy"

df_ret["Health_Bucket"] = df_ret["Health_Rank"].apply(health_bucket)

df_ret_final = df_ret.sort_values("Health_Rank").reset_index(drop=True)
df_ret_final


df_ret_final.to_csv("feature_health-rank.csv")

#Features_Health_Heatmap

RE_df_sorted = df_ret_final.sort_values("Health_Rank").reset_index(drop=True)
RE_heat_data = RE_df_sorted[["Health_Rank"]].to_numpy()

boundaries = [0, 12, 18, 22, 30, 40]
bucket_colors = [
    "#00E6E6", 
    "#C56BFF", 
    "#FF6BD9",  
    "#6B8BFF",  
    "#B6FF6B", 
]
cmap = mcolors.ListedColormap(bucket_colors)
norm = mcolors.BoundaryNorm(boundaries, cmap.N)

plt.figure(figsize=(12, 22))

# Heatmap
ax = sns.heatmap(
    RE_heat_data,
    cmap=cmap,
    norm=norm,
    cbar=True,
    linewidths=0.3,
    linecolor="white",
    yticklabels=RE_df_sorted["feature_name"],
    xticklabels=["Health_Rank"],
    annot=RE_df_sorted["Health_Bucket"].values.reshape(-1, 1),
    fmt="",
    annot_kws={
        "color": "white",
        "fontsize": 9,
        "fontweight": "bold",
        "ha": "center",
        "va": "center"
    }
)

plt.title(
    "Retained Feature Health Map",
    fontsize=22,
    color="white",
    pad=20
)

ax.set_xticklabels(ax.get_xticklabels(), color="white", fontsize=12)
ax.set_yticklabels(ax.get_yticklabels(), color="white", fontsize=10)

cbar = ax.collections[0].colorbar
cbar.set_ticks([6, 15, 20, 26, 35])
cbar.set_ticklabels([
    "Weak",
    "Below Average",
    "Average",
    "Healthy",
    "Very Healthy",
])

for tick in cbar.ax.get_yticklabels():
    tick.set_color("white")
    tick.set_fontsize(10)

plt.tight_layout()
plt.savefig(
    "Features_Health_Heatmap.png",
    dpi=300,
    bbox_inches="tight",
    facecolor=plt.gcf().get_facecolor()
)

plt.show()	

#Health_bucket_donut

order = [
   "Weak",
    "Below Average",
    "Average",
    "Healthy",
    "Very Healthy",
]

base_colors = {
    "Weak": "#00E6E6",
    "Below Average": "#C56BFF",
    "Average": "#FF6BD9",
    "Healthy": "#6B8BFF",
    "Very Healthy": "#B6FF6B"
}

bucket_counts = (
    RE_df_sorted["Health_Bucket"]
    .value_counts()
    .reindex(order)
    .fillna(0)
    .astype(int)
    .values
)

labels_order = order
colors = [base_colors[k] for k in labels_order]

def lighten(hexcolor, amount=0.25):
    rgb = np.array(mcolors.to_rgb(hexcolor))
    return tuple(rgb + (1 - rgb) * amount)

outer_colors = [lighten(c, 0.35) for c in colors]

fig, ax = plt.subplots(figsize=(9, 9), facecolor="#0C0420")
ax.set_facecolor("#0C0420")

# Outer donut
wedges_outer, _ = ax.pie(
    bucket_counts,
    radius=1.0,
    colors=outer_colors,
    startangle=90,
    wedgeprops=dict(width=0.25, edgecolor="#0C0420", linewidth=1.2)
)

# Inner donut
wedges_inner, _ = ax.pie(
    bucket_counts,
    radius=0.75,
    colors=colors,
    startangle=90,
    wedgeprops=dict(width=0.35, edgecolor="#0C0420", linewidth=1.2)
)

# Center hole
ax.add_artist(plt.Circle((0, 0), 0.40, color="#0A0318", zorder=10))

total = bucket_counts.sum()

for w_outer, count, label in zip(wedges_outer, bucket_counts, labels_order):
    theta1, theta2 = w_outer.theta1, w_outer.theta2
    mid = (theta1 + theta2) / 2
    angle = np.deg2rad(mid)

    # Position between rings
    r = 0.875
    x = r * np.cos(angle)
    y = r * np.sin(angle)

    pct = f"{(count / total) * 100:.1f}%"

    # If slice is tiny, move label slightly inward
    if abs(theta2 - theta1) < 10:
        x *= 0.88
        y *= 0.88

    ax.text(
        x, y, pct,
        ha="center", va="center",
        color="white", fontsize=13, fontweight="bold",
        bbox=dict(boxstyle="round,pad=0.2", facecolor="#00000033", edgecolor="none")
    )

plt.title("Retained Feature Health Bucket Distribution",
          fontsize=26, color="#F4EBD0", pad=24, weight="bold")

legend_patches = [
    plt.Line2D([0], [0], marker='s', color='w', markerfacecolor=colors[i], markersize=14)
    for i in range(len(colors))
]

ax.legend(
    legend_patches, labels_order,
    title="Health Buckets",
    loc="center left", bbox_to_anchor=(1.02, 0.5),
    frameon=True, facecolor="#0C0420", edgecolor="#FFFFFF40",
    fontsize=12, title_fontsize=14
)

plt.tight_layout()
plt.savefig(
    "Health_bucket_donut.png",
    dpi=300,
    bbox_inches="tight",
    facecolor=plt.gcf().get_facecolor()
)

plt.show()

# 5. Feature Ranking (Risk + Health)


combined = pd.merge(
    df_churn_final[['feature_name', 'Risk_Rank', 'Risk_Bucket']],
    df_ret_final[['feature_name', 'Health_Rank', 'Health_Bucket']],
    on='feature_name',
    how='inner'
)
combined['Final_Rank'] = combined[['Risk_Rank', 'Health_Rank']].mean(axis=1)

def final_bucket(score):
    """
    Final score interpretation:
    Lower score → Higher danger.
    Higher score → More stable and healthy.
    """
    if score <= 12:
        return "Critical / Very Unhealthy"
    if score <= 18:
        return "High Risk / Unhealthy"
    if score <= 22:
        return "Medium / Average"
    if score <= 30:
        return "Low Risk / Healthy"
    return "No Risk / Very Healthy"

combined['Final_Bucket'] = combined['Final_Rank'].apply(final_bucket)

def insight(row):
    r = row["Risk_Bucket"]
    h = row["Health_Bucket"]

    # CRITICAL: Both churn-risky + unhealthy usage
    if r in ["Critical", "High Risk"] and h in ["Weak", "Below Average"]:
        return "Immediate Action Needed"

    # High churn risk but product-side health looks OK → something is off
    if r in ["Critical", "High Risk"] and h in ["Average", "Healthy", "Very Healthy"]:
        return "Investigate Root Causes"

    # Medium churn risk + poor health → users struggle with the feature
    if r == "Medium Risk" and h in ["Weak", "Below Average"]:
        return "Requires Fixes Soon"

    # Low churn risk but poor health → retention hazard brewing
    if r in ["Low Risk", "No Risk"] and h in ["Weak", "Below Average"]:
        return "Retention Issue — Monitor"

    # Medium risk + healthy → normal variance
    if r == "Medium Risk" and h in ["Average", "Healthy", "Very Healthy"]:
        return "Moderate Priority"

    # Low risk + healthy → stable
    if r in ["Low Risk", "No Risk"] and h in ["Healthy", "Very Healthy"]:
        return "Stable / Good"

    return "Mixed — Needs Review"

combined['Final_Insight'] = combined.apply(insight, axis=1)

combined = combined.sort_values('Final_Rank', ascending=True).reset_index(drop=True)

combined.to_csv("feature-final-rank.csv")

#Final_Action_Heatmap

df_sorted = combined.sort_values("Final_Rank").reset_index(drop=True)
heat_data = df_sorted[["Final_Rank"]].to_numpy()

boundaries = [0, 12, 18, 22, 30, 40]
bucket_colors = [
    "#00E6E6",  
    "#C56BFF",  
    "#FF6BD9",  
    "#6B8BFF",  
    "#B6FF6B",  
]
cmap = mcolors.ListedColormap(bucket_colors)
norm = mcolors.BoundaryNorm(boundaries, cmap.N)

plt.figure(figsize=(12, 22))

# Heatmap
ax = sns.heatmap(
    heat_data,
    cmap=cmap,
    norm=norm,
    cbar=True,
    linewidths=0.3,
    linecolor="white",
    yticklabels=df_sorted["feature_name"],
    xticklabels=["Final_Rank"],
    annot=df_sorted["Final_Insight"].values.reshape(-1, 1),
    fmt="",
    annot_kws={
        "color": "white",
        "fontsize": 9,
        "fontweight": "bold",
        "ha": "center",
        "va": "center"
    }
)

plt.title(
    "Final Feature Action Map — Based on Risk + Health",
    fontsize=22,
    color="white",
    pad=20
)

ax.set_xticklabels(ax.get_xticklabels(), color="white", fontsize=12)
ax.set_yticklabels(ax.get_yticklabels(), color="white", fontsize=10)

cbar = ax.collections[0].colorbar
cbar.set_ticks([6, 15, 20, 26, 35])
cbar.set_ticklabels([
    "Critical Zone",
    "High Risk Zone",
    "Medium Zone",
    "Healthy Zone",
    "Very Healthy Zone",
])

for tick in cbar.ax.get_yticklabels():
    tick.set_color("white")
    tick.set_fontsize(10)

plt.tight_layout()
plt.savefig(
    "Final_Action_Heatmap.png",
    dpi=300,
    bbox_inches="tight",
    facecolor=plt.gcf().get_facecolor()
)

plt.show()

#final_bucket_donut

order = [
    "Critical / Very Unhealthy",
    "High Risk / Unhealthy",
    "Medium / Average",
    "Low Risk / Healthy",
    "No Risk / Very Healthy"
]

base_colors = {
    "Critical / Very Unhealthy": "#00E6E6",
    "High Risk / Unhealthy": "#C56BFF",
    "Medium / Average": "#FF6BD9",
    "Low Risk / Healthy": "#6B8BFF",
    "No Risk / Very Healthy": "#B6FF6B"
}

# Count values from your combined table
bucket_counts = (
    combined["Final_Bucket"]
    .value_counts()
    .reindex(order)
    .fillna(0)
    .astype(int)
    .values
)

labels_order = order
colors = [base_colors[k] for k in labels_order]

def lighten(hexcolor, amount=0.25):
    rgb = np.array(mcolors.to_rgb(hexcolor))
    return tuple(rgb + (1 - rgb) * amount)

outer_colors = [lighten(c, 0.35) for c in colors]

fig, ax = plt.subplots(figsize=(9, 9), facecolor="#0C0420")
ax.set_facecolor("#0C0420")

wedges_outer, _ = ax.pie(
    bucket_counts,
    radius=1.0,
    colors=outer_colors,
    startangle=90,
    wedgeprops=dict(width=0.25, edgecolor="#0C0420", linewidth=1.2)
)

wedges_inner, _ = ax.pie(
    bucket_counts,
    radius=0.75,
    colors=colors,
    startangle=90,
    wedgeprops=dict(width=0.35, edgecolor="#0C0420", linewidth=1.2)
)

ax.add_artist(plt.Circle((0, 0), 0.40, color="#0A0318", zorder=10))

total = bucket_counts.sum()

for w_outer, count, label in zip(wedges_outer, bucket_counts, labels_order):
    theta1, theta2 = w_outer.theta1, w_outer.theta2
    mid = (theta1 + theta2) / 2
    angle = np.deg2rad(mid)

    # Position between rings
    r = 0.875
    x = r * np.cos(angle)
    y = r * np.sin(angle)

    pct = f"{(count / total) * 100:.1f}%"
    if abs(theta2 - theta1) < 10:
        x *= 0.88
        y *= 0.88

    ax.text(
        x, y, pct,
        ha="center", va="center",
        color="white", fontsize=13, fontweight="bold",
        bbox=dict(boxstyle="round,pad=0.2", facecolor="#00000033", edgecolor="none")
    )

plt.title("Final Feature Risk–Health Bucket Distribution",
          fontsize=26, color="#F4EBD0", pad=24, weight="bold")

legend_patches = [
    plt.Line2D([0], [0], marker='s', color='w', markerfacecolor=colors[i], markersize=14)
    for i in range(len(colors))
]

ax.legend(
    legend_patches, labels_order,
    title="Final Buckets",
    loc="center left", bbox_to_anchor=(1.02, 0.5),
    frameon=True, facecolor="#0C0420", edgecolor="#FFFFFF40",
    fontsize=12, title_fontsize=14
)

plt.tight_layout()
plt.savefig(
    "final_bucket_donut.png",
    dpi=300,
    bbox_inches="tight",
    facecolor=plt.gcf().get_facecolor()
)

plt.show()

#risk-vs-health-vs-final plot

final_df_sorted = combined.sort_values("Final_Rank").reset_index(drop=True)

plt.figure(figsize=(28, 6))

plt.plot(final_df_sorted["feature_name"], final_df_sorted["Risk_Rank"], 
         marker='o',linewidth=3, color="#FF6BD9", label="Risk Rank")

plt.plot(final_df_sorted["feature_name"], final_df_sorted["Health_Rank"], 
         marker='o',linewidth=3, color="#00E6E6", label="Health Rank")

plt.plot(final_df_sorted["feature_name"], final_df_sorted["Final_Rank"], 
         marker='o',linewidth=4, color="#F2E0D2", label="Final Rank")

plt.xticks(rotation=80)

plt.title("Risk vs Health vs Final Rank (Combined)")
plt.xlabel("Feature Name")
plt.ylabel("Rank Score")

plt.gca().invert_xaxis()
plt.grid(alpha=0.2)
plt.legend(facecolor="#0A0318", edgecolor="#E6E6E6", labelcolor="#E6E6E6")
plt.savefig("Risk_vs_Health_vs_Final_Rank.jpg")

plt.tight_layout()
plt.savefig(
    "risk-vs-health-vs-final.png",
  
)
plt.show()

